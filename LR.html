<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Linear Regression Explained</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        :root {
            --background: #ffffff;
            --foreground: #252525;
            --card: #ffffff;
            --card-foreground: #252525;
            --muted: #ececf0;
            --muted-foreground: #717182;
            --border: rgba(0, 0, 0, 0.1);
            --radius: 0.625rem;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background-color: var(--background);
            color: var(--foreground);
            line-height: 1.5;
            font-size: 16px;
        }

        .container {
            max-width: 1024px;
            margin: 0 auto;
            padding: 1.5rem;
        }

        .space-y-8 > * + * {
            margin-top: 2rem;
        }

        .space-y-6 > * + * {
            margin-top: 1.5rem;
        }

        .space-y-4 > * + * {
            margin-top: 1rem;
        }

        .space-y-2 > * + * {
            margin-top: 0.5rem;
        }

        .header {
            text-align: center;
            padding: 2rem 0;
        }

        h1 {
            font-size: 2rem;
            font-weight: 500;
            margin-bottom: 1rem;
        }

        h2 {
            font-size: 1.5rem;
            font-weight: 500;
            margin-bottom: 0.5rem;
        }

        h3 {
            font-size: 1.25rem;
            font-weight: 500;
            margin-bottom: 0.5rem;
        }

        h4 {
            font-size: 1rem;
            font-weight: 500;
            margin-bottom: 0.5rem;
        }

        p {
            font-size: 1rem;
            font-weight: 400;
        }

        .text-muted {
            color: var(--muted-foreground);
        }

        .card {
            background: var(--card);
            border: 1px solid var(--border);
            border-radius: var(--radius);
            overflow: hidden;
        }

        .card-padding {
            padding: 1.5rem;
        }

        .aspect-video {
            position: relative;
            width: 100%;
            padding-bottom: 56.25%;
        }

        .aspect-video iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }

        .code-block {
            background: #0f172a;
            color: #f8fafc;
            padding: 1rem;
            border-radius: var(--radius);
            overflow-x: auto;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.875rem;
            line-height: 1.6;
        }

        .code-inline {
            background: var(--muted);
            padding: 0.75rem 1rem;
            border-radius: var(--radius);
            display: block;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9rem;
        }

        .code-inline.mt-2 {
            margin-top: 0.5rem;
        }

        ul {
            list-style: disc;
            padding-left: 2.5rem;
        }

        ul li {
            margin: 0.5rem 0;
        }

        strong {
            font-weight: 600;
        }

        .tabs {
            width: 100%;
        }

        .tabs-list {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 0.25rem;
            background: var(--muted);
            padding: 0.25rem;
            border-radius: var(--radius);
            margin-bottom: 1rem;
        }

        .tab-trigger {
            padding: 0.5rem 1rem;
            background: transparent;
            border: none;
            cursor: pointer;
            font-size: 0.875rem;
            font-weight: 500;
            border-radius: calc(var(--radius) - 2px);
            transition: background 0.2s;
        }

        .tab-trigger:hover {
            background: rgba(0, 0, 0, 0.05);
        }

        .tab-trigger.active {
            background: white;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .tab-content {
            display: none;
        }

        .tab-content.active {
            display: block;
        }

        .grid-gap-4 {
            display: grid;
            gap: 1rem;
        }

        .footer {
            text-align: center;
            padding: 2rem 0;
            color: var(--muted-foreground);
            border-top: 1px solid var(--border);
            margin-top: 2rem;
        }

        pre {
            margin: 0;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        code {
            font-family: 'Courier New', Courier, monospace;
        }

        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }

            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.25rem;
            }

            .code-block {
                font-size: 0.75rem;
            }
        }
    </style>
</head>
<body>
    <div class="container space-y-8">
        <!-- Header -->
        <div class="header space-y-4">
            <h1>Linear Regression Explained</h1>
            <p class="text-muted">
                A comprehensive guide to understanding linear regression with mathematical concepts and code examples
            </p>
        </div>

        <!-- YouTube Video Embed -->
        <div class="card">
            <div class="aspect-video">
                <iframe
                    width="100%"
                    height="100%"
                    src="https://www.youtube.com/embed/nk2CQITm_eo"
                    title="Linear Regression Tutorial"
                    frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen
                ></iframe>
            </div>
        </div>

        <!-- Introduction -->
        <section class="space-y-4">
            <h2>What is Linear Regression?</h2>
            <p>
                Linear regression is a fundamental supervised learning algorithm used to model the relationship between a dependent variable and one or more independent variables. It assumes a linear relationship between the input variables (features) and the output variable (target).
            </p>
            <p>
                The goal is to find the best-fitting straight line (or hyperplane in higher dimensions) through the data points that minimizes the prediction error.
            </p>
        </section>

        <!-- Mathematical Concepts -->
        <section class="space-y-6">
            <h2>Mathematical Foundation</h2>
            
            <div class="card card-padding space-y-4">
                <h3>The Linear Equation</h3>
                <p>
                    For simple linear regression with one feature, the equation is:
                </p>
                <div class="code-inline">
                    y = mx + b
                </div>
                <div class="code-inline mt-2">
                    or equivalently: y = β₀ + β₁x
                </div>
                <ul class="space-y-2">
                    <li><strong>y</strong>: predicted value (dependent variable)</li>
                    <li><strong>x</strong>: input feature (independent variable)</li>
                    <li><strong>β₀ (b)</strong>: y-intercept (bias term)</li>
                    <li><strong>β₁ (m)</strong>: slope (weight/coefficient)</li>
                </ul>
            </div>

            <div class="card card-padding space-y-4">
                <h3>Multiple Linear Regression</h3>
                <p>
                    For multiple features, the equation extends to:
                </p>
                <div class="code-inline">
                    y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ
                </div>
                <p>
                    Or in matrix form:
                </p>
                <div class="code-inline">
                    Y = Xβ + ε
                </div>
                <ul class="space-y-2">
                    <li><strong>Y</strong>: vector of predicted values</li>
                    <li><strong>X</strong>: matrix of input features</li>
                    <li><strong>β</strong>: vector of coefficients</li>
                    <li><strong>ε</strong>: error term</li>
                </ul>
            </div>

            <div class="card card-padding space-y-4">
                <h3>Cost Function (Mean Squared Error)</h3>
                <p>
                    The cost function measures how well our model fits the data:
                </p>
                <div class="code-inline">
                    MSE = (1/n) × Σ(yᵢ - ŷᵢ)²
                </div>
                <ul class="space-y-2">
                    <li><strong>n</strong>: number of data points</li>
                    <li><strong>yᵢ</strong>: actual value</li>
                    <li><strong>ŷᵢ</strong>: predicted value</li>
                </ul>
                <p style="margin-top: 1rem;">
                    The goal is to minimize this cost function by finding optimal values for β₀ and β₁.
                </p>
            </div>

            <div class="card card-padding space-y-4">
                <h3>Normal Equation</h3>
                <p>
                    The closed-form solution to find optimal coefficients:
                </p>
                <div class="code-inline">
                    β = (XᵀX)⁻¹Xᵀy
                </div>
                <p>
                    This directly computes the best parameters without needing iterative optimization.
                </p>
            </div>
        </section>

        <!-- Code Implementation -->
        <section class="space-y-6">
            <h2>Code Implementation</h2>

            <div class="tabs">
                <div class="tabs-list">
                    <button class="tab-trigger active" onclick="switchTab('python')">Python (NumPy)</button>
                    <button class="tab-trigger" onclick="switchTab('sklearn')">Scikit-learn</button>
                </div>

                <div id="python-tab" class="tab-content active space-y-4">
                    <div class="card card-padding">
                        <h3>Simple Linear Regression from Scratch</h3>
                        <p style="margin-bottom: 1rem;">
                            Let's implement linear regression using only NumPy:
                        </p>
                        <div class="code-block">
                            <pre><code>import numpy as np

class LinearRegression:
    def __init__(self):
        """Initialize the linear regression model"""
        self.slope = None
        self.intercept = None
    
    def fit(self, X, y):
        """
        Train the model using the normal equation
        
        Parameters:
        X: Input features (n_samples, n_features)
        y: Target values (n_samples,)
        """
        # Add bias term (column of ones) to X
        X_b = np.c_[np.ones((X.shape[0], 1)), X]
        
        # Normal equation: β = (XᵀX)⁻¹Xᵀy
        theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)
        
        # Extract intercept and slope
        self.intercept = theta[0]
        self.slope = theta[1:]
    
    def predict(self, X):
        """
        Make predictions on new data
        
        Parameters:
        X: Input features (n_samples, n_features)
        
        Returns:
        predictions: Predicted values
        """
        return self.intercept + X.dot(self.slope)
    
    def score(self, X, y):
        """
        Calculate R² score
        
        Returns:
        R² score (coefficient of determination)
        """
        y_pred = self.predict(X)
        ss_res = np.sum((y - y_pred) ** 2)
        ss_tot = np.sum((y - np.mean(y)) ** 2)
        return 1 - (ss_res / ss_tot)

# Example usage
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([2, 4, 5, 4, 6])

model = LinearRegression()
model.fit(X, y)

print(f"Slope: {model.slope[0]:.2f}")
print(f"Intercept: {model.intercept:.2f}")
print(f"R² Score: {model.score(X, y):.3f}")

# Make predictions
X_new = np.array([[6], [7]])
predictions = model.predict(X_new)
print(f"Predictions: {predictions}")</code></pre>
                        </div>
                    </div>

                    <div class="card card-padding">
                        <h3>Gradient Descent Implementation</h3>
                        <p style="margin-bottom: 1rem;">
                            Alternative approach using gradient descent optimization:
                        </p>
                        <div class="code-block">
                            <pre><code>import numpy as np

class LinearRegressionGD:
    def __init__(self, learning_rate=0.01, n_iterations=1000):
        """
        Initialize with hyperparameters
        
        Parameters:
        learning_rate: Step size for gradient descent
        n_iterations: Number of training iterations
        """
        self.lr = learning_rate
        self.n_iterations = n_iterations
        self.weights = None
        self.bias = None
        self.cost_history = []
    
    def fit(self, X, y):
        """Train using gradient descent"""
        n_samples, n_features = X.shape
        
        # Initialize parameters
        self.weights = np.zeros(n_features)
        self.bias = 0
        
        # Gradient descent
        for i in range(self.n_iterations):
            # Forward pass: compute predictions
            y_pred = np.dot(X, self.weights) + self.bias
            
            # Compute cost (MSE)
            cost = (1 / n_samples) * np.sum((y_pred - y) ** 2)
            self.cost_history.append(cost)
            
            # Compute gradients
            dw = (2 / n_samples) * np.dot(X.T, (y_pred - y))
            db = (2 / n_samples) * np.sum(y_pred - y)
            
            # Update parameters
            self.weights -= self.lr * dw
            self.bias -= self.lr * db
    
    def predict(self, X):
        """Make predictions"""
        return np.dot(X, self.weights) + self.bias

# Example usage
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([2, 4, 5, 4, 6])

model = LinearRegressionGD(learning_rate=0.01, n_iterations=1000)
model.fit(X, y)

print(f"Final weights: {model.weights}")
print(f"Final bias: {model.bias:.2f}")
print(f"Final cost: {model.cost_history[-1]:.4f}")</code></pre>
                        </div>
                    </div>
                </div>

                <div id="sklearn-tab" class="tab-content space-y-4">
                    <div class="card card-padding">
                        <h3>Using Scikit-learn</h3>
                        <p style="margin-bottom: 1rem;">
                            The most common way to use linear regression in practice:
                        </p>
                        <div class="code-block">
                            <pre><code>from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Generate sample data
X = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])
y = np.array([2.1, 3.9, 6.2, 8.1, 9.8, 12.3, 14.1, 15.9, 18.2, 20.1])

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Create and train the model
model = LinearRegression()
model.fit(X_train, y_train)

# Get model parameters
print(f"Coefficient (slope): {model.coef_[0]:.3f}")
print(f"Intercept: {model.intercept_:.3f}")

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"\nMean Squared Error: {mse:.3f}")
print(f"R² Score: {r2:.3f}")

# Predict new values
X_new = np.array([[11], [12]])
predictions = model.predict(X_new)
print(f"\nPredictions for X=11,12: {predictions}")</code></pre>
                        </div>
                    </div>

                    <div class="card card-padding">
                        <h3>Multiple Linear Regression Example</h3>
                        <p style="margin-bottom: 1rem;">
                            Working with multiple features:
                        </p>
                        <div class="code-block">
                            <pre><code>from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
import numpy as np

# Generate data with multiple features
# Features: [square_feet, bedrooms, age]
X = np.array([
    [1500, 3, 10],
    [2000, 4, 5],
    [1200, 2, 15],
    [1800, 3, 8],
    [2500, 4, 2],
    [1600, 3, 12],
    [2200, 4, 6],
    [1400, 2, 20]
])

# Target: house price (in thousands)
y = np.array([300, 400, 250, 350, 500, 320, 450, 280])

# Feature scaling (important for gradient-based methods)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train the model
model = LinearRegression()
model.fit(X_scaled, y)

# Display coefficients
feature_names = ['Square Feet', 'Bedrooms', 'Age']
print("Feature Importance:")
for name, coef in zip(feature_names, model.coef_):
    print(f"  {name}: {coef:.2f}")

print(f"\nIntercept: {model.intercept_:.2f}")
print(f"R² Score: {model.score(X_scaled, y):.3f}")

# Predict for a new house: 1700 sq ft, 3 bedrooms, 7 years old
X_new = np.array([[1700, 3, 7]])
X_new_scaled = scaler.transform(X_new)
predicted_price = model.predict(X_new_scaled)
print(f"\nPredicted price: ${predicted_price[0]:.2f}k")</code></pre>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Key Concepts -->
        <section class="space-y-6">
            <h2>Key Concepts Explained</h2>

            <div class="grid-gap-4">
                <div class="card card-padding">
                    <h3>1. Assumptions of Linear Regression</h3>
                    <ul class="space-y-2" style="margin-top: 0.75rem;">
                        <li><strong>Linearity:</strong> The relationship between X and y is linear</li>
                        <li><strong>Independence:</strong> Observations are independent of each other</li>
                        <li><strong>Homoscedasticity:</strong> Constant variance of errors</li>
                        <li><strong>Normality:</strong> Residuals are normally distributed</li>
                        <li><strong>No multicollinearity:</strong> Features are not highly correlated</li>
                    </ul>
                </div>

                <div class="card card-padding">
                    <h3>2. Evaluation Metrics</h3>
                    <div class="space-y-4" style="margin-top: 0.75rem;">
                        <div>
                            <h4>Mean Squared Error (MSE)</h4>
                            <div class="code-inline" style="margin-top: 0.5rem;">
                                MSE = (1/n) × Σ(yᵢ - ŷᵢ)²
                            </div>
                            <p style="margin-top: 0.5rem;">Average squared difference between predictions and actual values. Lower is better.</p>
                        </div>
                        <div>
                            <h4>R² Score (Coefficient of Determination)</h4>
                            <div class="code-inline" style="margin-top: 0.5rem;">
                                R² = 1 - (SS_res / SS_tot)
                            </div>
                            <p style="margin-top: 0.5rem;">Proportion of variance explained by the model. Ranges from 0 to 1, higher is better.</p>
                        </div>
                        <div>
                            <h4>Root Mean Squared Error (RMSE)</h4>
                            <div class="code-inline" style="margin-top: 0.5rem;">
                                RMSE = √MSE
                            </div>
                            <p style="margin-top: 0.5rem;">Square root of MSE. In the same units as the target variable.</p>
                        </div>
                    </div>
                </div>

                <div class="card card-padding">
                    <h3>3. When to Use Linear Regression</h3>
                    <ul class="space-y-2" style="margin-top: 0.75rem;">
                        <li>Predicting continuous numerical values</li>
                        <li>Understanding relationships between variables</li>
                        <li>When you need an interpretable model</li>
                        <li>As a baseline model before trying complex algorithms</li>
                        <li>When you have a linear relationship in your data</li>
                    </ul>
                </div>

                <div class="card card-padding">
                    <h3>4. Limitations</h3>
                    <ul class="space-y-2" style="margin-top: 0.75rem;">
                        <li>Only models linear relationships</li>
                        <li>Sensitive to outliers</li>
                        <li>Assumes features are independent</li>
                        <li>May underfit complex patterns</li>
                        <li>Requires careful feature engineering for non-linear data</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- Footer -->
        <div class="footer">
            <p>Keep learning and experimenting with linear regression!</p>
        </div>
    </div>

    <script>
        function switchTab(tabName) {
            // Hide all tab contents
            const contents = document.querySelectorAll('.tab-content');
            contents.forEach(content => {
                content.classList.remove('active');
            });

            // Deactivate all tab triggers
            const triggers = document.querySelectorAll('.tab-trigger');
            triggers.forEach(trigger => {
                trigger.classList.remove('active');
            });

            // Show selected tab content
            const selectedContent = document.getElementById(tabName + '-tab');
            if (selectedContent) {
                selectedContent.classList.add('active');
            }

            // Activate clicked trigger
            event.target.classList.add('active');
        }
    </script>
</body>
</html>
